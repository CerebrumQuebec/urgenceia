Word to Markdown
Results of converting IA et données personnelles \_ le Québec face au pillage algorithmique - Philippe Bourque.docx
Markdown
**IA et données personnelles : le Québec face au pillage algorithmique**

L'intelligence artificielle transforme notre monde à une vitesse vertigineuse, mais dans l'ombre de cette révolution se cache une réalité méconnue : l'entraînement d'un modèle d'IA est un acte techniquement irréversible. Une fois nos données intégrées aux poids mathématiques de ces systèmes, il devient impossible d'en effacer précisément la trace. Lorsque ces modèles sont ensuite distribués en code source ouvert, chaque copie se multiplie à travers le monde, rendant toute violation initiale permanente et globale.

D'ici à un mois, Meta commencera à ingérer les publications européennes pour entraîner son intelligence artificielle. En Australie, c'est déjà chose faite, sans possibilité d'opposition réelle : photos de famille, visages d'enfants, créations artistiques, tout devient carburant algorithmique. Pourquoi penser que le Québec serait épargné? Rien n'indique que Meta ou d'autres géants technologiques aient respecté leur obligation légale d'obtenir un consentement explicite des Québécois pour cette utilisation radicalement nouvelle de leurs données personnelles.

Or, au Québec, la Loi 25 est particulièrement claire et rigoureuse : tout usage commercial nouveau de renseignements personnels exige un consentement manifeste, libre et éclairé. L'entraînement d'une IA commerciale ne faisait certainement pas partie des intentions initiales des utilisateurs de plateformes comme Facebook, Instagram, ou YouTube. Toute collecte sans consentement constituerait donc une violation majeure de notre législation. Les sanctions potentielles sont considérables : jusqu'à 4% du chiffre d'affaires mondial pour les infractions graves pour les entreprises (plus de 7 milliards de dollars canadiens pour Meta seule) et jusqu'à 100 000 dollars d'amende personnelle pour les dirigeants, assortie d'un casier judiciaire au Québec.

Au-delà de la protection des données personnelles, le droit d'auteur canadien protège également chaque œuvre diffusée sur ces plateformes, avec des indemnisations pouvant atteindre 20 000 dollars par infraction. Considérant les millions d'œuvres québécoises concernées, l'ampleur du préjudice potentiel est stupéfiante.

Plus alarmant encore : plusieurs de ces entreprises ont déjà reconnu utiliser massivement des données de réseaux sociaux. Meta exploite ouvertement les contenus de Facebook et Instagram pour ses modèles LLaMA. Google a modifié sa politique pour pouvoir utiliser toutes les données publiques du web, incluant YouTube. OpenAI a conclu un partenariat avec Reddit après avoir exploité ses données pendant des années. xAI de Elon Musk puise directement dans X/Twitter. Anthropic, bien que plus discret, invoque le « fair use » pour justifier l'utilisation de contenus protégés.

Cet argument du « fair use », brandi par certaines entreprises comme bouclier juridique, s'effondre toutefois face à notre cadre légal. La Loi 25 ne s'intéresse pas à la transformation des données, mais à l'existence d'un consentement explicite pour leur utilisation. Sur ce point fondamental, la loi est limpide : sans consentement, l'infraction est caractérisée, peu importe que les données soient « transformées » plutôt que « copiées ».

J'appelle donc la Commission d'accès à l'information du Québec à exiger sans délai la publication des Évaluations des facteurs relatifs à la vie privée (EFVP) de ces entreprises pour leurs projets d'IA concernant des données québécoises. Je demande que toute collecte soit suspendue jusqu'à l'obtention du consentement explicite requis par la loi. J'invite le ministre Gilles Bélanger, responsable de la Cybersécurité et du Numérique, et le ministre Mathieu Lacombe, responsable de la Culture et des Communications, à unir leurs efforts pour protéger notre patrimoine numérique et culturel.

Je sollicite également tous les partis politiques afin qu'ils déposent une motion unanime pour défendre les droits fondamentaux des Québécois face à cette extraction massive de données personnelles et culturelles. Les géants technologiques, qui accumulent des fortunes colossales grâce à cette exploitation sans frein, doivent comprendre que personne n'est au-dessus des lois québécoises.

La situation est d'autant plus préoccupante que chaque modèle d'IA entraîné pourrait constituer une infraction distincte. Avec Meta, Google, OpenAI et autres qui déploient de nouvelles versions de leurs modèles tous les quelques mois, le préjudice et les pénalités potentielles se multiplient à un rythme vertigineux – possiblement plus d'une centaine de milliards de dollars.

Agir, oui, mais agir maintenant. Chaque jour perdu nous rapproche d'un point de non-retour. Si la CAI manque de ressources ou hésite à affronter seule ces géants, alors créons une coalition de citoyens, d'artistes, de juristes et d'experts pour l'appuyer. Collectivement, le Québec s'est doté d'une loi robuste et d'institutions capables de la faire respecter. Il est temps de démontrer que notre souveraineté numérique n'est pas qu'un concept abstrait.

Ces propos sont formulés de bonne foi dans le cadre d'un débat public essentiel pour la protection des droits fondamentaux des citoyens québécois et pour la préservation de notre patrimoine culturel à l'ère numérique.!
Philippe Bourque, Bs. ING

Artiste, entrepreneur et scientifique  
Saint-François-de-l'île-d'Orléans  
6 mai 2025  
<br/>T-AI-2 -> [badgeAI.org](http://badgeai.org)

**Cosignataires**

**(ajouter votre nom complet ici, votre titre et votre courriel)**

Philippe Bourque, Bs. ING - Fondateur de Cérebrum - [phil@cerebrum.website](mailto:phil@cerebrum.website)

**Annexe 1 - Validation des faits par Grok 3 en mode DeeperSearch**

- Les faits de votre lettre d'opinion semblent globalement exacts, mais certains détails sur les amendes et le consentement nécessitent des clarifications.
- Contexte de Meta et de l'IA : Il semble probable que Meta utilise des données publiques pour entraîner ses modèles d'IA, comme en Europe et en Australie, sans option de refus pour les utilisateurs australiens.
- Loi 25 au Québec : La recherche suggère que la Loi 25 exige un consentement explicite pour l'utilisation de données personnelles, avec des amendes pouvant atteindre 4 % du chiffre d'affaires mondial pour les infractions pénales et 2 % pour les amendes administratives.
- Droit d'auteur canadien : Les dommages-intérêts pour violation de copyright peuvent atteindre 20 000 $ par œuvre pour des usages commerciaux, ce qui est exact.
- Pratiques d'autres entreprises : Il est confirmé que Google, OpenAI, xAI et Anthropic utilisent des données publiques pour l'entraînement d'IA, avec Anthropic invoquant l'usage équitable dans des litiges.
- Appel à l'action : La Commission d'accès à l'information du Québec (CAI) s'implique dans les enjeux de confidentialité liés à l'IA, soutenant votre appel à des mesures.

#### **Détails sur Meta et l'IA**

Meta a annoncé en avril 2025 qu'elle commencerait à utiliser les données publiques des utilisateurs européens pour entraîner ses modèles d'IA, avec une option de refus. En Australie, Meta utilise déjà ces données sans possibilité de refus, ce qui soulève des inquiétudes pour le Québec, où aucune information spécifique n'indique un consentement explicite pour les utilisateurs québécois.

#### **Exigences légales sous la Loi 25**

La Loi 25 exige un consentement explicite, libre et éclairé pour tout nouvel usage commercial des données personnelles, y compris l'entraînement d'IA. Les amendes peuvent aller jusqu'à 4 % du chiffre d'affaires mondial pour les infractions pénales et 2 % pour les amendes administratives, avec des amendes personnelles jusqu'à 100 000 $ pour les dirigeants. Votre mention de 2 % semble se référer aux amendes administratives, mais les infractions graves peuvent entraîner des pénalités plus élevées. <sup>Note de Philippe Bourque : Suite à cette analyse, j’ai modifié mon texte pour y mettre 4%.</sup>

#### **Protection du droit d'auteur**

Le droit d'auteur canadien permet des dommages-intérêts statutaires de 500 à 20 000 $ par œuvre pour des usages commerciaux, confirmant votre affirmation.

### **Rapport détaillé**

Votre lettre d'opinion sur l'IA et la protection des données personnelles au Québec, en particulier concernant l'entraînement des modèles d'IA par des entreprises comme Meta, soulève des points importants. Voici une analyse détaillée des faits présentés, en s'appuyant sur des recherches récentes et des informations disponibles jusqu'au 6 mai 2025.

#### **Contexte et pratiques de Meta**

Votre affirmation selon laquelle Meta commencera à ingérer les publications européennes pour entraîner son intelligence artificielle d'ici un mois est corroborée par des annonces récentes. Par exemple, le 14 avril 2025, Meta a déclaré qu'elle utiliserait les données publiques partagées par les adultes sur ses plateformes en Union européenne pour entraîner ses modèles d'IA, après avoir obtenu l'approbation des régulateurs ([Meta to use public posts, AI interactions to train models in EU | Reuters](https://www.reuters.com/technology/artificial-intelligence/meta-use-public-posts-ai-interactions-train-models-eu-2025-04-14/)). Les utilisateurs européens recevront des notifications avec une option de refus, ce qui contraste avec la situation en Australie, où Meta utilise déjà les données publiques sans possibilité de refus, comme confirmé en septembre 2024 ([Meta admits to using Australian users' data for AI training](https://www.newsbytesapp.com/news/science/meta-is-scraping-user-data-in-australia-for-ai-training/story)). Pour le Québec, aucune information spécifique n'indique que Meta a obtenu un consentement explicite des utilisateurs, ce qui soulève des questions de conformité avec la Loi 25.

#### **Exigences légales sous la Loi 25**

La Loi 25, officiellement l'« Acte de modernisation des dispositions législatives en matière de protection des renseignements personnels », exige un consentement manifeste, libre et éclairé pour tout nouvel usage commercial des données personnelles, y compris l'entraînement d'IA commerciale, ce qui n'était probablement pas dans les intentions initiales des utilisateurs de plateformes comme Facebook ou Instagram ([Quebec's Law 25: Everything you need to know | Didomi](https://www.didomi.io/blog/quebec-data-privacy-law)). Les sanctions pour non-conformité incluent des amendes administratives allant jusqu'à 10 millions de dollars ou 2 % du chiffre d'affaires mondial, et des amendes pénales pouvant atteindre 25 millions de dollars ou 4 % du chiffre d'affaires mondial, selon la gravité ([Quebec Law 25 Update - Latest Obligations Effective September 2023 | McCarthy Tétrault](https://www.mccarthy.ca/en/insights/blogs/techlex/quebec-law-25-update-latest-obligations-effective-september-2023)). Pour les dirigeants, les amendes peuvent atteindre 100 000 $, avec possibilité de casier judiciaire, ce qui correspond à votre mention. Cependant, votre référence à « jusqu'à 2 % du chiffre d'affaires mondial » semble se limiter aux amendes administratives, alors que les infractions graves peuvent entraîner des pénalités plus élevées. <sup>Note de Philippe Bourque : Suite à cette analyse, j’ai modifié mon texte pour y mettre 4%.</sup>

| **Type de sanction**    | **Montant maximum**                        | **Remarque**                                             |
| ----------------------- | ------------------------------------------ | -------------------------------------------------------- |
| Amendes administratives | 10 M$ ou 2 % du chiffre d'affaires mondial | Pour non-conformité générale                             |
| ---                     | ---                                        | ---                                                      |
| Amendes pénales         | 25 M$ ou 4 % du chiffre d'affaires mondial | Pour infractions graves, peut doubler en cas de récidive |
| ---                     | ---                                        | ---                                                      |
| Amendes pour individus  | 100 000 $                                  | Avec possibilité de casier judiciaire                    |
| ---                     | ---                                        | ---                                                      |

#### **Protection du droit d'auteur canadien**

Votre mention des indemnisations pouvant atteindre 20 000 $ par infraction est exacte pour les usages commerciaux. Selon la Loi sur le droit d'auteur, les dommages-intérêts statutaires pour une infraction commerciale varient de 500 à 20 000 $ par œuvre, tandis que pour les usages non commerciaux, ils vont de 100 à 5 000 $ pour toutes les œuvres en cause ([Copyright infringement and fair dealing | Legal Line](https://www.legalline.ca/legal-answers/copyright-infringement-and-fair-dealing/)). Avec des millions d'œuvres québécoises potentiellement concernées, l'ampleur des préjudices est effectivement significative.

#### **Pratiques d'autres entreprises**

Vous mentionnez que plusieurs entreprises utilisent massivement des données de réseaux sociaux pour entraîner leurs modèles d'IA, ce qui est confirmé :

- Meta : Utilise ouvertement les contenus de Facebook et Instagram pour ses modèles LLaMA, comme mentionné dans les annonces récentes ([Meta Resumes E.U. AI Training Using Public User Data After Regulator Approval](https://thehackernews.com/2025/04/meta-resumes-eu-ai-training-using.html)).
- Google : A modifié sa politique pour utiliser toutes les données publiques du web, y compris YouTube, pour entraîner ses modèles d'IA, comme indiqué dans une mise à jour de juillet 2023 ([Google’s updated privacy policy doubles down on using your data for training AI](https://9to5google.com/2023/07/03/google-privacy-policy-ai-training-data/)).
- OpenAI : A conclu un partenariat avec Reddit en mai 2024, permettant d'accéder à son API de données pour entraîner ses modèles, y compris ChatGPT ([OpenAI, Reddit teaming in deal that will bring Reddit's content to ChatGPT | AP News](https://apnews.com/article/reddit-openai-chatgpt-bd2291fcc226bc737a44dbef4a31563f)).
- xAI : Utilise les tweets publics pour entraîner ses modèles, comme déclaré par Elon Musk en juillet 2023 ([Elon Musk says xAI will use public tweets for AI model training | Reuters](https://www.reuters.com/technology/elon-musk-says-xai-will-use-public-tweets-ai-model-training-2023-07-14/)).
- Anthropic : Invoque l'usage équitable (« fair use ») dans des litiges de copyright, arguant que l'entraînement de son modèle Claude sur des données web publiques, y compris potentiellement protégées, est transformateur, comme vu dans une motion de mars 2025 ([Anthropic Says 'Fair Use' Dooms Authors' AI Copyright Lawsuit | Bloomberg Law](https://news.bloomberglaw.com/ip-law/anthropic-says-fair-use-dooms-authors-ai-copyright-lawsuit)).

| **Entreprise** | **Source de données**                     | **Remarque**                               |
| -------------- | ----------------------------------------- | ------------------------------------------ |
| Meta           | Facebook, Instagram (public posts)        | Utilisé pour LLaMA, sans opt-out au Québec |
| ---            | ---                                       | ---                                        |
| Google         | Données web publiques, incl. YouTube      | Politique mise à jour en 2023              |
| ---            | ---                                       | ---                                        |
| OpenAI         | Partenariat Reddit, API de données        | Accès en temps réel depuis mai 2024        |
| ---            | ---                                       | ---                                        |
| xAI            | Tweets publics                            | Déclaration de Musk en juillet 2023        |
| ---            | ---                                       | ---                                        |
| Anthropic      | Données web publiques, invoquant fair use | Défense dans litiges de copyright          |
| ---            | ---                                       | ---                                        |

#### **Argument contre l'usage équitable**

Vous affirmez que l'argument de l'usage équitable s'effondre face à la Loi 25, qui ne s'intéresse pas à la transformation des données mais à l'existence d'un consentement explicite. Cela est exact pour la protection des données personnelles : la Loi 25 exige un consentement pour l'utilisation, peu importe si les données sont transformées ou non, contrairement au droit d'auteur où l'usage équitable peut être invoqué ([Quebec's Law 25: Everything you need to know | Didomi](https://www.didomi.io/blog/quebec-data-privacy-law)). Cette distinction est cruciale, car les entreprises doivent se conformer aux exigences de consentement, indépendamment de la transformation algorithmique.

#### **Appel à l'action**

Votre appel à la CAI pour exiger la publication des Évaluations des facteurs relatifs à la vie privée (EFVP) et suspendre la collecte de données jusqu'à obtention du consentement est pertinent. La CAI s'implique dans les enjeux d'IA, notamment via une enquête conjointe en mai 2023 sur ChatGPT avec d'autres autorités canadiennes, examinant la collecte de données sans consentement ([La Commission d’accès à l’information enquêtera conjointement sur ChatGPT avec le Commissariat fédéral et des autorités provinciales | CAI](https://www.cai.gouv.qc.ca/actualites/commission-acces-information-enquetera-conjointement-sur-chatgpt-avec-commissariat-federal-et-autorites-provinciales-protection-vie-privee)). De plus, en décembre 2023, la CAI a dévoilé des principes pour un développement responsable de l'IA générative, soulignant l'importance de la protection de la vie privée ([Dévoilement des principes de développement et d’utilisation de l’intelligence artificielle (IA) générative | CAI](https://www.cai.gouv.qc.ca/actualites/devoilement-principes-developpement-et-utilisation-intelligence-artificielle-ia-generative)). Votre sollicitation des ministres et des partis politiques pour une motion unanime est également justifiée, étant donné l'ampleur des enjeux.

En résumé, les faits de votre lettre sont largement corroborés, avec une clarification sur les amendes (jusqu'à 4 % pour les infractions pénales) et une confirmation de l'implication de la CAI dans les enjeux d'IA, soutenant votre appel à l'action.

### **Citations clés**

- [Meta to use public posts, AI interactions to train models in EU | Reuters](https://www.reuters.com/technology/artificial-intelligence/meta-use-public-posts-ai-interactions-train-models-eu-2025-04-14/)
- [Meta admits to using Australian users' data for AI training](https://www.newsbytesapp.com/news/science/meta-is-scraping-user-data-in-australia-for-ai-training/story)
- [Quebec's Law 25: Everything you need to know | Didomi](https://www.didomi.io/blog/quebec-data-privacy-law)
- [Quebec Law 25 Update - Latest Obligations Effective September 2023 | McCarthy Tétrault](https://www.mccarthy.ca/en/insights/blogs/techlex/quebec-law-25-update-latest-obligations-effective-september-2023)
- [Copyright infringement and fair dealing | Legal Line](https://www.legalline.ca/legal-answers/copyright-infringement-and-fair-dealing/)
- [Google’s updated privacy policy doubles down on using your data for training AI](https://9to5google.com/2023/07/03/google-privacy-policy-ai-training-data/)
- [OpenAI, Reddit teaming in deal that will bring Reddit's content to ChatGPT | AP News](https://apnews.com/article/reddit-openai-chatgpt-bd2291fcc226bc737a44dbef4a31563f)
- [Elon Musk says xAI will use public tweets for AI model training | Reuters](https://www.reuters.com/technology/elon-musk-says-xai-will-use-public-tweets-ai-model-training-2023-07-14/)
- [Anthropic Says 'Fair Use' Dooms Authors' AI Copyright Lawsuit | Bloomberg Law](https://news.bloomberglaw.com/ip-law/anthropic-says-fair-use-dooms-authors-ai-copyright-lawsuit)
- [La Commission d’accès à l’information enquêtera conjointement sur ChatGPT avec le Commissariat fédéral et des autorités provinciales | CAI](https://www.cai.gouv.qc.ca/actualites/commission-acces-information-enquetera-conjointement-sur-chatgpt-avec-commissariat-federal-et-autorites-provinciales-protection-vie-privee)
- [Dévoilement des principes de développement et d’utilisation de l’intelligence artificielle (IA) générative | CAI](https://www.cai.gouv.qc.ca/actualites/devoilement-principes-developpement-et-utilisation-intelligence-artificielle-ia-generative)

Analyse révisée par Philippe Bourque

T-AI-3 -> [badgeAI.org](http://badgeai.org)

**Annexe 2 - Analyse du consentement explicite de Google pour l’entraînement d’IA par Grok 3**

Ce rapport examine si les changements de politique de confidentialité de Google en 2023 constituent un consentement explicite pour l’utilisation de données personnelles dans l’entraînement de modèles d’intelligence artificielle (IA), en lien avec les exigences de la Loi 25 au Québec.

**Contexte des changements de politique de Google**

En juillet 2023, Google a mis à jour sa politique de confidentialité pour autoriser l’utilisation de données publiques (ex. : vidéos YouTube, commentaires) dans l’entraînement de ses modèles d’IA, comme Bard. Les utilisateurs ont été informés via des courriels ou notifications avec des liens vers des documents juridiques complexes, sans explication claire de l’usage pour l’IA ni de ses implications, comme l’irréversibilité des données intégrées dans les modèles \[1\].

**Exigences de la Loi 25**

La Loi 25 exige un consentement **manifeste**, **libre**, **éclairé** et **spécifique** pour tout nouvel usage commercial des données personnelles, y compris l’entraînement d’IA. Cela inclut les données publiques liées à un individu identifiable (ex. : publications YouTube). L’utilisateur doit comprendre l’objectif et les conséquences, comme l’impossibilité de retirer ses données d’un modèle IA \[2\].

**Analyse des pratiques de Google**

Les pratiques de Google en 2023 ne répondent pas aux critères de la Loi 25 :

- **Notifications vagues** : Les courriels de mise à jour, envoyés fréquemment, contiennent du jargon juridique sans détailler l’entraînement d’IA ou son irréversibilité. Cela ne permet pas un consentement éclairé \[3\].
- **Absence d’opt-out clair** : Google a introduit un outil (Google-Extended) pour les éditeurs de sites web, mais pas pour les utilisateurs individuels. Aucun mécanisme simple n’a été offert pour refuser l’utilisation des données personnelles \[1\].
- **Consentement implicite** : Continuer à utiliser les services Google est interprété comme un accord, ce qui contrevient à l’exigence d’une action positive (ex. : cocher une case) \[2\].
- **Manque de transparence** : L’irréversibilité de l’entraînement d’IA n’est pas expliquée, privant les utilisateurs d’une compréhension complète des enjeux.

**Expérience personnelle de Philippe Bourque**

En tant qu’utilisateur de 12 comptes Google, Philippe Bourque n’a aucun souvenir d’une explication claire sur l’utilisation de mes données pour l’IA, d’une option d’opt-out accessible, ou d’une mention de l’irréversibilité. Les notifications fréquentes, noyées dans un langage juridique, sont ignorées, reflétant un problème systémique où le consentement est présumé, non obtenu \[3\].

**Implications pour la Loi 25**

L’utilisation de données personnelles sans consentement explicite constitue une violation potentielle de la Loi 25, passible d’amendes allant jusqu’à 4 % du chiffre d’affaires mondial de Google. Cela renforce l’urgence d’une intervention de la Commission d’accès à l’information (CAI) pour exiger des Évaluations des facteurs relatifs à la vie privée et suspendre ces pratiques \[4\].

**Conclusion**

Les changements de politique de Google en 2023 s’appuient sur un consentement implicite, loin des standards de la Loi 25. L’absence de transparence, d’opt-out clair et d’information sur l’irréversibilité prive les Québécois d’un contrôle réel sur leurs données. Ce rapport soutient l’appel à une action immédiate pour protéger la vie privée et la souveraineté numérique.

**Références**

\[1\] <https://9to5google.com/2023/07/03/google-privacy-policy-ai-training-data/>  
\[2\] <https://www.didomi.io/blog/quebec-data-privacy-law>  
\[3\] <https://gizmodo.com/google-says-itll-scrape-everything-you-post-online-for-1850601486>  
\[4\] <https://www.mccarthy.ca/en/insights/blogs/techlex/quebec-law-25-update-latest-obligations-effective-september-2023>

Analyse révisée par Philippe Bourque

T-AI-3 -> [badgeAI.org](http://badgeai.org)
Rendered
IA et données personnelles : le Québec face au pillage algorithmique

L'intelligence artificielle transforme notre monde à une vitesse vertigineuse, mais dans l'ombre de cette révolution se cache une réalité méconnue : l'entraînement d'un modèle d'IA est un acte techniquement irréversible. Une fois nos données intégrées aux poids mathématiques de ces systèmes, il devient impossible d'en effacer précisément la trace. Lorsque ces modèles sont ensuite distribués en code source ouvert, chaque copie se multiplie à travers le monde, rendant toute violation initiale permanente et globale.

D'ici à un mois, Meta commencera à ingérer les publications européennes pour entraîner son intelligence artificielle. En Australie, c'est déjà chose faite, sans possibilité d'opposition réelle : photos de famille, visages d'enfants, créations artistiques, tout devient carburant algorithmique. Pourquoi penser que le Québec serait épargné? Rien n'indique que Meta ou d'autres géants technologiques aient respecté leur obligation légale d'obtenir un consentement explicite des Québécois pour cette utilisation radicalement nouvelle de leurs données personnelles.

Or, au Québec, la Loi 25 est particulièrement claire et rigoureuse : tout usage commercial nouveau de renseignements personnels exige un consentement manifeste, libre et éclairé. L'entraînement d'une IA commerciale ne faisait certainement pas partie des intentions initiales des utilisateurs de plateformes comme Facebook, Instagram, ou YouTube. Toute collecte sans consentement constituerait donc une violation majeure de notre législation. Les sanctions potentielles sont considérables : jusqu'à 4% du chiffre d'affaires mondial pour les infractions graves pour les entreprises (plus de 7 milliards de dollars canadiens pour Meta seule) et jusqu'à 100 000 dollars d'amende personnelle pour les dirigeants, assortie d'un casier judiciaire au Québec.

Au-delà de la protection des données personnelles, le droit d'auteur canadien protège également chaque œuvre diffusée sur ces plateformes, avec des indemnisations pouvant atteindre 20 000 dollars par infraction. Considérant les millions d'œuvres québécoises concernées, l'ampleur du préjudice potentiel est stupéfiante.

Plus alarmant encore : plusieurs de ces entreprises ont déjà reconnu utiliser massivement des données de réseaux sociaux. Meta exploite ouvertement les contenus de Facebook et Instagram pour ses modèles LLaMA. Google a modifié sa politique pour pouvoir utiliser toutes les données publiques du web, incluant YouTube. OpenAI a conclu un partenariat avec Reddit après avoir exploité ses données pendant des années. xAI de Elon Musk puise directement dans X/Twitter. Anthropic, bien que plus discret, invoque le « fair use » pour justifier l'utilisation de contenus protégés.

Cet argument du « fair use », brandi par certaines entreprises comme bouclier juridique, s'effondre toutefois face à notre cadre légal. La Loi 25 ne s'intéresse pas à la transformation des données, mais à l'existence d'un consentement explicite pour leur utilisation. Sur ce point fondamental, la loi est limpide : sans consentement, l'infraction est caractérisée, peu importe que les données soient « transformées » plutôt que « copiées ».

J'appelle donc la Commission d'accès à l'information du Québec à exiger sans délai la publication des Évaluations des facteurs relatifs à la vie privée (EFVP) de ces entreprises pour leurs projets d'IA concernant des données québécoises. Je demande que toute collecte soit suspendue jusqu'à l'obtention du consentement explicite requis par la loi. J'invite le ministre Gilles Bélanger, responsable de la Cybersécurité et du Numérique, et le ministre Mathieu Lacombe, responsable de la Culture et des Communications, à unir leurs efforts pour protéger notre patrimoine numérique et culturel.

Je sollicite également tous les partis politiques afin qu'ils déposent une motion unanime pour défendre les droits fondamentaux des Québécois face à cette extraction massive de données personnelles et culturelles. Les géants technologiques, qui accumulent des fortunes colossales grâce à cette exploitation sans frein, doivent comprendre que personne n'est au-dessus des lois québécoises.

La situation est d'autant plus préoccupante que chaque modèle d'IA entraîné pourrait constituer une infraction distincte. Avec Meta, Google, OpenAI et autres qui déploient de nouvelles versions de leurs modèles tous les quelques mois, le préjudice et les pénalités potentielles se multiplient à un rythme vertigineux – possiblement plus d'une centaine de milliards de dollars.

Agir, oui, mais agir maintenant. Chaque jour perdu nous rapproche d'un point de non-retour. Si la CAI manque de ressources ou hésite à affronter seule ces géants, alors créons une coalition de citoyens, d'artistes, de juristes et d'experts pour l'appuyer. Collectivement, le Québec s'est doté d'une loi robuste et d'institutions capables de la faire respecter. Il est temps de démontrer que notre souveraineté numérique n'est pas qu'un concept abstrait.

Ces propos sont formulés de bonne foi dans le cadre d'un débat public essentiel pour la protection des droits fondamentaux des citoyens québécois et pour la préservation de notre patrimoine culturel à l'ère numérique.

Philippe Bourque, Bs. ING

Artiste, entrepreneur et scientifique
Saint-François-de-l'île-d'Orléans
6 mai 2025
T-AI-2 -> badgeAI.org

Cosignataires

(ajouter votre nom complet ici, votre titre et votre courriel)

Philippe Bourque, Bs. ING - Fondateur de Cérebrum - phil@cerebrum.website

Annexe 1 - Validation des faits par Grok 3 en mode DeeperSearch

Les faits de votre lettre d'opinion semblent globalement exacts, mais certains détails sur les amendes et le consentement nécessitent des clarifications.
Contexte de Meta et de l'IA : Il semble probable que Meta utilise des données publiques pour entraîner ses modèles d'IA, comme en Europe et en Australie, sans option de refus pour les utilisateurs australiens.
Loi 25 au Québec : La recherche suggère que la Loi 25 exige un consentement explicite pour l'utilisation de données personnelles, avec des amendes pouvant atteindre 4 % du chiffre d'affaires mondial pour les infractions pénales et 2 % pour les amendes administratives.
Droit d'auteur canadien : Les dommages-intérêts pour violation de copyright peuvent atteindre 20 000 $ par œuvre pour des usages commerciaux, ce qui est exact.
Pratiques d'autres entreprises : Il est confirmé que Google, OpenAI, xAI et Anthropic utilisent des données publiques pour l'entraînement d'IA, avec Anthropic invoquant l'usage équitable dans des litiges.
Appel à l'action : La Commission d'accès à l'information du Québec (CAI) s'implique dans les enjeux de confidentialité liés à l'IA, soutenant votre appel à des mesures.
Détails sur Meta et l'IA
Meta a annoncé en avril 2025 qu'elle commencerait à utiliser les données publiques des utilisateurs européens pour entraîner ses modèles d'IA, avec une option de refus. En Australie, Meta utilise déjà ces données sans possibilité de refus, ce qui soulève des inquiétudes pour le Québec, où aucune information spécifique n'indique un consentement explicite pour les utilisateurs québécois.

Exigences légales sous la Loi 25
La Loi 25 exige un consentement explicite, libre et éclairé pour tout nouvel usage commercial des données personnelles, y compris l'entraînement d'IA. Les amendes peuvent aller jusqu'à 4 % du chiffre d'affaires mondial pour les infractions pénales et 2 % pour les amendes administratives, avec des amendes personnelles jusqu'à 100 000 $ pour les dirigeants. Votre mention de 2 % semble se référer aux amendes administratives, mais les infractions graves peuvent entraîner des pénalités plus élevées. Note de Philippe Bourque : Suite à cette analyse, j’ai modifié mon texte pour y mettre 4%.

Protection du droit d'auteur
Le droit d'auteur canadien permet des dommages-intérêts statutaires de 500 à 20 000 $ par œuvre pour des usages commerciaux, confirmant votre affirmation.

Rapport détaillé
Votre lettre d'opinion sur l'IA et la protection des données personnelles au Québec, en particulier concernant l'entraînement des modèles d'IA par des entreprises comme Meta, soulève des points importants. Voici une analyse détaillée des faits présentés, en s'appuyant sur des recherches récentes et des informations disponibles jusqu'au 6 mai 2025.

Contexte et pratiques de Meta
Votre affirmation selon laquelle Meta commencera à ingérer les publications européennes pour entraîner son intelligence artificielle d'ici un mois est corroborée par des annonces récentes. Par exemple, le 14 avril 2025, Meta a déclaré qu'elle utiliserait les données publiques partagées par les adultes sur ses plateformes en Union européenne pour entraîner ses modèles d'IA, après avoir obtenu l'approbation des régulateurs (Meta to use public posts, AI interactions to train models in EU | Reuters). Les utilisateurs européens recevront des notifications avec une option de refus, ce qui contraste avec la situation en Australie, où Meta utilise déjà les données publiques sans possibilité de refus, comme confirmé en septembre 2024 (Meta admits to using Australian users' data for AI training). Pour le Québec, aucune information spécifique n'indique que Meta a obtenu un consentement explicite des utilisateurs, ce qui soulève des questions de conformité avec la Loi 25.

Exigences légales sous la Loi 25
La Loi 25, officiellement l'« Acte de modernisation des dispositions législatives en matière de protection des renseignements personnels », exige un consentement manifeste, libre et éclairé pour tout nouvel usage commercial des données personnelles, y compris l'entraînement d'IA commerciale, ce qui n'était probablement pas dans les intentions initiales des utilisateurs de plateformes comme Facebook ou Instagram (Quebec's Law 25: Everything you need to know | Didomi). Les sanctions pour non-conformité incluent des amendes administratives allant jusqu'à 10 millions de dollars ou 2 % du chiffre d'affaires mondial, et des amendes pénales pouvant atteindre 25 millions de dollars ou 4 % du chiffre d'affaires mondial, selon la gravité (Quebec Law 25 Update - Latest Obligations Effective September 2023 | McCarthy Tétrault). Pour les dirigeants, les amendes peuvent atteindre 100 000 $, avec possibilité de casier judiciaire, ce qui correspond à votre mention. Cependant, votre référence à « jusqu'à 2 % du chiffre d'affaires mondial » semble se limiter aux amendes administratives, alors que les infractions graves peuvent entraîner des pénalités plus élevées. Note de Philippe Bourque : Suite à cette analyse, j’ai modifié mon texte pour y mettre 4%.

Type de sanction Montant maximum Remarque
Amendes administratives 10 M$ ou 2 % du chiffre d'affaires mondial Pour non-conformité générale

---

Amendes pénales 25 M$ ou 4 % du chiffre d'affaires mondial Pour infractions graves, peut doubler en cas de récidive

---

Amendes pour individus 100 000 $ Avec possibilité de casier judiciaire

---

Protection du droit d'auteur canadien
Votre mention des indemnisations pouvant atteindre 20 000 $ par infraction est exacte pour les usages commerciaux. Selon la Loi sur le droit d'auteur, les dommages-intérêts statutaires pour une infraction commerciale varient de 500 à 20 000 $ par œuvre, tandis que pour les usages non commerciaux, ils vont de 100 à 5 000 $ pour toutes les œuvres en cause (Copyright infringement and fair dealing | Legal Line). Avec des millions d'œuvres québécoises potentiellement concernées, l'ampleur des préjudices est effectivement significative.

Pratiques d'autres entreprises
Vous mentionnez que plusieurs entreprises utilisent massivement des données de réseaux sociaux pour entraîner leurs modèles d'IA, ce qui est confirmé :

Meta : Utilise ouvertement les contenus de Facebook et Instagram pour ses modèles LLaMA, comme mentionné dans les annonces récentes (Meta Resumes E.U. AI Training Using Public User Data After Regulator Approval).
Google : A modifié sa politique pour utiliser toutes les données publiques du web, y compris YouTube, pour entraîner ses modèles d'IA, comme indiqué dans une mise à jour de juillet 2023 (Google’s updated privacy policy doubles down on using your data for training AI).
OpenAI : A conclu un partenariat avec Reddit en mai 2024, permettant d'accéder à son API de données pour entraîner ses modèles, y compris ChatGPT (OpenAI, Reddit teaming in deal that will bring Reddit's content to ChatGPT | AP News).
xAI : Utilise les tweets publics pour entraîner ses modèles, comme déclaré par Elon Musk en juillet 2023 (Elon Musk says xAI will use public tweets for AI model training | Reuters).
Anthropic : Invoque l'usage équitable (« fair use ») dans des litiges de copyright, arguant que l'entraînement de son modèle Claude sur des données web publiques, y compris potentiellement protégées, est transformateur, comme vu dans une motion de mars 2025 (Anthropic Says 'Fair Use' Dooms Authors' AI Copyright Lawsuit | Bloomberg Law).
Entreprise Source de données Remarque
Meta Facebook, Instagram (public posts) Utilisé pour LLaMA, sans opt-out au Québec

---

Google Données web publiques, incl. YouTube Politique mise à jour en 2023

---

OpenAI Partenariat Reddit, API de données Accès en temps réel depuis mai 2024

---

xAI Tweets publics Déclaration de Musk en juillet 2023

---

Anthropic Données web publiques, invoquant fair use Défense dans litiges de copyright

---

Argument contre l'usage équitable
Vous affirmez que l'argument de l'usage équitable s'effondre face à la Loi 25, qui ne s'intéresse pas à la transformation des données mais à l'existence d'un consentement explicite. Cela est exact pour la protection des données personnelles : la Loi 25 exige un consentement pour l'utilisation, peu importe si les données sont transformées ou non, contrairement au droit d'auteur où l'usage équitable peut être invoqué (Quebec's Law 25: Everything you need to know | Didomi). Cette distinction est cruciale, car les entreprises doivent se conformer aux exigences de consentement, indépendamment de la transformation algorithmique.

Appel à l'action
Votre appel à la CAI pour exiger la publication des Évaluations des facteurs relatifs à la vie privée (EFVP) et suspendre la collecte de données jusqu'à obtention du consentement est pertinent. La CAI s'implique dans les enjeux d'IA, notamment via une enquête conjointe en mai 2023 sur ChatGPT avec d'autres autorités canadiennes, examinant la collecte de données sans consentement (La Commission d’accès à l’information enquêtera conjointement sur ChatGPT avec le Commissariat fédéral et des autorités provinciales | CAI). De plus, en décembre 2023, la CAI a dévoilé des principes pour un développement responsable de l'IA générative, soulignant l'importance de la protection de la vie privée (Dévoilement des principes de développement et d’utilisation de l’intelligence artificielle (IA) générative | CAI). Votre sollicitation des ministres et des partis politiques pour une motion unanime est également justifiée, étant donné l'ampleur des enjeux.

En résumé, les faits de votre lettre sont largement corroborés, avec une clarification sur les amendes (jusqu'à 4 % pour les infractions pénales) et une confirmation de l'implication de la CAI dans les enjeux d'IA, soutenant votre appel à l'action.

Citations clés
Meta to use public posts, AI interactions to train models in EU | Reuters
Meta admits to using Australian users' data for AI training
Quebec's Law 25: Everything you need to know | Didomi
Quebec Law 25 Update - Latest Obligations Effective September 2023 | McCarthy Tétrault
Copyright infringement and fair dealing | Legal Line
Google’s updated privacy policy doubles down on using your data for training AI
OpenAI, Reddit teaming in deal that will bring Reddit's content to ChatGPT | AP News
Elon Musk says xAI will use public tweets for AI model training | Reuters
Anthropic Says 'Fair Use' Dooms Authors' AI Copyright Lawsuit | Bloomberg Law
La Commission d’accès à l’information enquêtera conjointement sur ChatGPT avec le Commissariat fédéral et des autorités provinciales | CAI
Dévoilement des principes de développement et d’utilisation de l’intelligence artificielle (IA) générative | CAI
Analyse révisée par Philippe Bourque

T-AI-3 -> badgeAI.org

Annexe 2 - Analyse du consentement explicite de Google pour l’entraînement d’IA par Grok 3

Ce rapport examine si les changements de politique de confidentialité de Google en 2023 constituent un consentement explicite pour l’utilisation de données personnelles dans l’entraînement de modèles d’intelligence artificielle (IA), en lien avec les exigences de la Loi 25 au Québec.

Contexte des changements de politique de Google

En juillet 2023, Google a mis à jour sa politique de confidentialité pour autoriser l’utilisation de données publiques (ex. : vidéos YouTube, commentaires) dans l’entraînement de ses modèles d’IA, comme Bard. Les utilisateurs ont été informés via des courriels ou notifications avec des liens vers des documents juridiques complexes, sans explication claire de l’usage pour l’IA ni de ses implications, comme l’irréversibilité des données intégrées dans les modèles [1].

Exigences de la Loi 25

La Loi 25 exige un consentement manifeste, libre, éclairé et spécifique pour tout nouvel usage commercial des données personnelles, y compris l’entraînement d’IA. Cela inclut les données publiques liées à un individu identifiable (ex. : publications YouTube). L’utilisateur doit comprendre l’objectif et les conséquences, comme l’impossibilité de retirer ses données d’un modèle IA [2].

Analyse des pratiques de Google

Les pratiques de Google en 2023 ne répondent pas aux critères de la Loi 25 :

Notifications vagues : Les courriels de mise à jour, envoyés fréquemment, contiennent du jargon juridique sans détailler l’entraînement d’IA ou son irréversibilité. Cela ne permet pas un consentement éclairé [3].
Absence d’opt-out clair : Google a introduit un outil (Google-Extended) pour les éditeurs de sites web, mais pas pour les utilisateurs individuels. Aucun mécanisme simple n’a été offert pour refuser l’utilisation des données personnelles [1].
Consentement implicite : Continuer à utiliser les services Google est interprété comme un accord, ce qui contrevient à l’exigence d’une action positive (ex. : cocher une case) [2].
Manque de transparence : L’irréversibilité de l’entraînement d’IA n’est pas expliquée, privant les utilisateurs d’une compréhension complète des enjeux.
Expérience personnelle de Philippe Bourque

En tant qu’utilisateur de 12 comptes Google, Philippe Bourque n’a aucun souvenir d’une explication claire sur l’utilisation de mes données pour l’IA, d’une option d’opt-out accessible, ou d’une mention de l’irréversibilité. Les notifications fréquentes, noyées dans un langage juridique, sont ignorées, reflétant un problème systémique où le consentement est présumé, non obtenu [3].

Implications pour la Loi 25

L’utilisation de données personnelles sans consentement explicite constitue une violation potentielle de la Loi 25, passible d’amendes allant jusqu’à 4 % du chiffre d’affaires mondial de Google. Cela renforce l’urgence d’une intervention de la Commission d’accès à l’information (CAI) pour exiger des Évaluations des facteurs relatifs à la vie privée et suspendre ces pratiques [4].

Conclusion

Les changements de politique de Google en 2023 s’appuient sur un consentement implicite, loin des standards de la Loi 25. L’absence de transparence, d’opt-out clair et d’information sur l’irréversibilité prive les Québécois d’un contrôle réel sur leurs données. Ce rapport soutient l’appel à une action immédiate pour protéger la vie privée et la souveraineté numérique.

Références

[1] https://9to5google.com/2023/07/03/google-privacy-policy-ai-training-data/
[2] https://www.didomi.io/blog/quebec-data-privacy-law
[3] https://gizmodo.com/google-says-itll-scrape-everything-you-post-online-for-1850601486
[4] https://www.mccarthy.ca/en/insights/blogs/techlex/quebec-law-25-update-latest-obligations-effective-september-2023

Analyse révisée par Philippe Bourque

T-AI-3 -> badgeAI.org

Feedback
Source
Donate
Terms
Privacy
@benbalter
